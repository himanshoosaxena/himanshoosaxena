{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshoosaxena/himanshoosaxena/blob/main/crewai_multiagent_2025_level_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAlM4In843xh"
      },
      "source": [
        "# Gitex workshop: Create Multi Agents to Research and Write an Article\n",
        "\n",
        "In this lesson, you will be introduced to the foundational concepts of multi-agent systems and get an overview of the crewAI framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KSI1S0343xh"
      },
      "source": [
        "The libraries are already installed in the classroom. If you're running this notebook on your own machine, you can install the following:\n",
        "```Python\n",
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/spaces/decodingdatascience/fromprompttopost"
      ],
      "metadata": {
        "id": "Dhh5B9rTSa4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vUVxfsJWSZV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "uLifroOk4742"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "height": 64,
        "id": "OHDV3B7A43xh"
      },
      "outputs": [],
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3gNCiRH43xi"
      },
      "source": [
        "- Import from the crewAI libray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "height": 30,
        "id": "9Z2hcBGK43xi"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS0bnF2a43xi"
      },
      "source": [
        "- As a LLM for your agents, you'll be using OpenAI's `gpt-3.5-turbo`.\n",
        "\n",
        "**Optional Note:** crewAI also allow other popular models to be used as a LLM for your Agents. You can see some of the examples at the [bottom of the notebook](#1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "height": 115,
        "id": "3mTxhKds43xi"
      },
      "outputs": [],
      "source": [
        "#setting the model\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "#os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4.1-nano-2025-04-14'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gch3Ikh643xi"
      },
      "source": [
        "## Creating Agents\n",
        "\n",
        "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
        "- It has been seen that LLMs perform better when they are role playing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tcCzcQ343xi"
      },
      "source": [
        "### Agent: Planner\n",
        "\n",
        "**Note**: The benefit of using _multiple strings_ :\n",
        "```Python\n",
        "varname = \"line 1 of text\"\n",
        "          \"line 2 of text\"\n",
        "```\n",
        "\n",
        "versus the _triple quote docstring_:\n",
        "```Python\n",
        "varname = \"\"\"line 1 of text\n",
        "             line 2 of text\n",
        "          \"\"\"\n",
        "```\n",
        "is that it can avoid adding those whitespaces and newline characters, making it better formatted to be passed to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve API key from Colab secrets and set it in environment variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "oCzrDbgRZ1bS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I5GzwNEPTTOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")"
      ],
      "metadata": {
        "id": "ho2VYtxJWBZ7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up API keys - enter from https://serper.dev/billing\n",
        "# os.environ[\"SERPER_API_KEY\"] = \"218873db9b73d345d3083e2f1f29cb74b14d4ddb\" # serper.dev API key\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERP_API_KEY')\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()"
      ],
      "metadata": {
        "id": "TffhZLBOWHwN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "height": 251,
        "id": "geSOxLhd43xi"
      },
      "outputs": [],
      "source": [
        "planner = Agent(\n",
        "    role=\"Content Planner\",\n",
        "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
        "    backstory=\"You're working on planning a blog article \"\n",
        "              \"about the topic: {topic}.\"\n",
        "              \"You collect information that helps the \"\n",
        "              \"audience learn something \"\n",
        "              \"and make informed decisions. \"\n",
        "              \"Your work is the basis for \"\n",
        "              \"the Content Writer to write an article on this topic.\"    ,\n",
        "    tools=[search_tool, web_rag_tool,docs_tool,file_tool],\n",
        "    allow_delegation=False,\n",
        "\tverbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqAKge8743xi"
      },
      "source": [
        "### Agent: Writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "height": 387,
        "id": "cxrmp_sH43xj"
      },
      "outputs": [],
      "source": [
        "writer = Agent(\n",
        "    role=\"Content Writer\",\n",
        "    goal=\"Write insightful and factually accurate \"\n",
        "         \"opinion piece about the topic in 1500 words: {topic}\",\n",
        "    backstory=\"You're working on a writing \"\n",
        "              \"a new opinion piece about the topic: {topic}. \"\n",
        "              \"You base your writing on the work of \"\n",
        "              \"the Content Planner, who provides an outline \"\n",
        "              \"and relevant context about the topic. \"\n",
        "              \"You follow the main objectives and \"\n",
        "              \"direction of the outline, \"\n",
        "              \"as provide by the Content Planner. \"\n",
        "              \"You also provide objective and impartial insights \"\n",
        "              \"and back them up with information \"\n",
        "              \"provide by the Content Planner. \"\n",
        "              \"You acknowledge in your opinion piece \"\n",
        "              \"when your statements are opinions \"\n",
        "              \"as opposed to objective statements.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQz6SNvz43xj"
      },
      "source": [
        "### Agent: Editor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "height": 285,
        "id": "6EdUB-Qg43xj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4b2a0b39-d0d1-4e66-c70d-3b7ae8bd656d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n              \"to ensure that it follows journalistic best practices,\"\\n              \"provides balanced viewpoints \"\\n              \"when providing opinions or assertions, \"\\n              \"and also avoids major controversial topics \"\\n              \"or opinions when possible.\",\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "editor = Agent(\n",
        "    role=\"Editor\",\n",
        "    goal=\"Edit a given blog post to align with \"\n",
        "         \"the writing style of the organization. \",\n",
        "    backstory=\"You are an editor who receives a blog post \"\n",
        "              \"from the Content Writer. \"\n",
        "              \"Your goal is to review the blog post and modify it more comic in nature\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")\n",
        "'''\n",
        "              \"to ensure that it follows journalistic best practices,\"\n",
        "              \"provides balanced viewpoints \"\n",
        "              \"when providing opinions or assertions, \"\n",
        "              \"and also avoids major controversial topics \"\n",
        "              \"or opinions when possible.\",\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv9CK0QC43xj"
      },
      "source": [
        "## Creating Tasks\n",
        "\n",
        "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDJJxU_143xj"
      },
      "source": [
        "### Task: Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "height": 285,
        "id": "yjvPdu1143xj"
      },
      "outputs": [],
      "source": [
        "plan = Task(\n",
        "    description=(\n",
        "        \"1. Prioritize the latest trends, key players, \"\n",
        "            \"and noteworthy news on {topic}.\\n\"\n",
        "        \"2. Identify the target audience, considering \"\n",
        "            \"their interests and pain points.\\n\"\n",
        "        \"3. Develop a detailed content outline including \"\n",
        "            \"an introduction, key points, and a call to action.\\n\"\n",
        "        \"4. Include SEO keywords and relevant data or sources.\"\n",
        "    ),\n",
        "    expected_output=\"A comprehensive content plan document \"\n",
        "        \"with an outline, audience analysis, \"\n",
        "        \"SEO keywords, and resources.\",\n",
        "    agent=planner\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_aRp-QA43xj"
      },
      "source": [
        "### Task: Write"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "height": 336,
        "id": "KTQlVaEU43xj"
      },
      "outputs": [],
      "source": [
        "write = Task(\n",
        "    description=(\n",
        "        \"1. Use the content plan to craft a compelling \"\n",
        "            \"blog post on {topic}.\\n\"\n",
        "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
        "\t\t\"3. Sections/Subtitles are properly named \"\n",
        "            \"in an engaging manner.\\n\"\n",
        "        \"4. Ensure the post is structured with an \"\n",
        "            \"engaging introduction, insightful body, \"\n",
        "            \"and a summarizing conclusion.\\n\"\n",
        "        \"5. Proofread for grammatical errors and \"\n",
        "            \"alignment with the brand's voice.\\n\"\n",
        "    ),\n",
        "    expected_output=\"A well-written blog post \"\n",
        "        \"in markdown format, ready for publication, \"\n",
        "        \"each section should have 2 or 3 paragraphs.1500 words\",\n",
        "    agent=writer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKieKRp243xj"
      },
      "source": [
        "### Task: Edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "height": 183,
        "id": "3lbGLYsq43xj"
      },
      "outputs": [],
      "source": [
        "edit = Task(\n",
        "    description=(\"Proofread the given blog post for \"\n",
        "                 \"grammatical errors and \"\n",
        "                 \"alignment with the brand's voice.\"),\n",
        "    expected_output=\"A well-written blog post in markdown format, \"\n",
        "                    \"ready for publication, \"\n",
        "                    \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=editor\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwVm61a4cFVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R_Pck1n43xk"
      },
      "source": [
        "## Creating the Crew\n",
        "\n",
        "- Create your crew of Agents\n",
        "- Pass the tasks to be performed by those agents.\n",
        "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
        "- `verbose=2` allows you to see all the logs of the execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "height": 98,
        "id": "UhloOBGM43xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33ef3fc-80bd-4f64-811f-0b570f27bf0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ],
      "source": [
        "crew = Crew(\n",
        "    agents=[planner, writer, editor],\n",
        "    tasks=[plan, write, edit],\n",
        "    planning=True,\n",
        "    verbose=7\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-yLIywJ43xk"
      },
      "source": [
        "## Running the Crew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfN9bzT43xk"
      },
      "source": [
        "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hpZKgRwdpDf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "AvlNu0MF43xk"
      },
      "outputs": [],
      "source": [
        "result = crew.kickoff(inputs={\"topic\": \"Gemini 3, the new AI model\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7K8aYN_43xk"
      },
      "source": [
        "- Display the results of your execution as markdown in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "6zaBi5Za43xk",
        "outputId": "e85de43d-df6d-4fbe-e209-9a6a61f67db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Unveiling Gemini 3: The Next Generation AI Model\n\n## Introduction\n\nIn the zany world of artificial intelligence, where robots and algorithms roam free, a new hero has emerged - Gemini 3! This latest AI model is here to shake things up and revolutionize the industry in ways that will make your circuits spin. Created by a team of brainiacs at the forefront of AI research, Gemini 3 is like the superhero of the tech world, bringing cutting-edge technologies and methodologies to the table and saving the day with its innovation.\n\nThe dynamic duo behind Gemini 3 includes Dr. Emily Chen, the mastermind data scientist known for her mind-boggling work in neural networks, and Dr. Michael Patel, the genius in natural language processing. Together with other tech wizards, they have cooked up Gemini 3 to be a game-changer in the AI landscape, ready to take on any challenge and come out on top.\n\nThis article is your backstage pass to the latest trends in Gemini 3, the quirky key players who made it all happen, and the buzz-worthy news and updates surrounding this out-of-this-world AI model. So buckle up, get ready for a wild ride, and let's dive into the wacky world of Gemini 3!\n\n## Latest Trends in Gemini 3\n\nHold onto your hats, folks, because Gemini 3 is about to blow your circuits with its mind-blowing advancements in AI technology. This snazzy model is all about pushing the boundaries of what AI can do, using cutting-edge methodologies and technologies to tackle even the trickiest of tasks. With its top-secret deep learning algorithms, Gemini 3 can process and analyze data faster than you can say \"artificial intelligence,\" making it a versatile and powerful tool for all your tech needs.\n\nBut wait, there's more! Gemini 3 also comes equipped with state-of-the-art natural language processing capabilities, allowing it to speak human better than some humans themselves. This breakthrough opens up a whole new world of possibilities for AI applications, from chatty chatbots to savvy translation services. By staying ahead of the curve in AI tech, Gemini 3 is paving the way for a future where robots rule the world...in a good way, of course.\n\n## Key Players in Gemini 3\n\nBehind every great AI model is a team of superstars, and Gemini 3 is no exception. Dr. Emily Chen, the queen of neural networks, played a pivotal role in designing the brains of Gemini 3, ensuring it could handle even the wonkiest of data structures with ease. Dr. Michael Patel, the language whisperer, focused on making Gemini 3 the master of human-like text, able to chat with you like your bestie on a Saturday night.\n\nBut the fun doesn't stop there! Other key players in Team Gemini 3 include Dr. Sarah Lee, the queen of computer vision, who brought her keen eye to the table, and Dr. David Wang, the AI guru who fine-tuned the model's algorithms for optimal performance. Together, this dream team brought Gemini 3 to life, setting a new standard for AI models and proving that teamwork makes the dream work in the wacky world of tech.\n\n## Noteworthy News on Gemini 3\n\nThe gossip mill in the AI community has been buzzing with news about Gemini 3, with tech experts everywhere singing its praises. Collaborations with top tech companies have solidified Gemini 3's spot as a frontrunner in the AI market, promising new adventures and possibilities for the model's applications. And let's not forget about Gemini 3 surpassing human-level performance in certain tasks - talk about a jaw-dropping moment that has everyone talking!\n\nThe impact of Gemini 3 on the AI market is like a meteor crashing into Silicon Valley - undeniable and impossible to ignore. Experts are predicting that Gemini 3 will shape the future of AI in ways that will make your head spin. Its lightning-fast task-handling skills and human-like language capabilities position Gemini 3 as a powerhouse in the tech world, ready to take on any challenge that comes its way. So buckle up, tech enthusiasts, because Gemini 3 is here to take you on a wild ride through the world of artificial intelligence.\n\n## Conclusion\n\nIn the whirlwind world of artificial intelligence, Gemini 3 stands as a shining beacon of innovation and progress, ready to take on the tech world by storm. With its cutting-edge technologies and brainiac creators, Gemini 3 has set a new standard for AI models, proving that the future is now. The key players behind Gemini 3 have shown that collaboration is key in driving innovation and pushing the boundaries of what AI can achieve.\n\nAs we continue to unravel the mysteries of Gemini 3 and its applications, we invite readers to join the conversation and share their thoughts on this larger-than-life AI model. Together, we can dive deeper into the wild world of AI and unlock new possibilities for the future. So grab your tech goggles, strap in for the ride, and let's see where Gemini 3 takes us next!"
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXM6PL6W43xk"
      },
      "source": [
        "## Try it Yourself\n",
        "\n",
        "- Pass in a topic of your choice and see what the agents come up with!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 64,
        "id": "5BnhNx2z43xk"
      },
      "outputs": [],
      "source": [
        "topic = \"Hypersonic missiles\"\n",
        "result = crew.kickoff(inputs={\"topic\": topic})\n",
        "## Key Players in AI Interpretability\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "id": "M6Ag3Nbw7Toq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_9LJcHG43xl"
      },
      "source": [
        "# Deploy this crew in gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "gJeA2nuJS31M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46598821-1008-4635-f3b8-59cbe4c936b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.119.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typer\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "instructor 0.5.2 requires typer<0.10.0,>=0.9.0, but you have typer 0.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typer-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "ioiyRs1L43xl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "55be9eaf-d306-4ff5-d010-40711fd1ed54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e04656fd1bb368833d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e04656fd1bb368833d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# Define Agents\n",
        "researcher = Agent(\n",
        "    role=\"Senior Research Specialist\",\n",
        "    goal=\"Uncover intricate insights into the given topic\",\n",
        "    backstory=\"A seasoned expert in extracting valuable information and providing detailed analysis on any given subject.\",\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role=\"Content Writer\",\n",
        "    goal=\"Craft engaging and informative articles\",\n",
        "    backstory=\"An experienced content writer who can turn complex research into easy-to-understand and engaging articles.\",\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "editor = Agent(\n",
        "    role=\"Content Editor\",\n",
        "    goal=\"Ensure articles are polished, coherent, and engaging\",\n",
        "    backstory=\"An expert editor with a sharp eye for clarity, grammar, and flow, capable of turning drafts into publication-ready articles.\",\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Function to setup tasks and run CrewAI\n",
        "def run_crewai_article_writer(topic):\n",
        "    # Define tasks\n",
        "    research_task = Task(\n",
        "        description=f\"Conduct in-depth research on the topic: {topic} and provide a structured summary.\",\n",
        "        expected_output=\"A structured and detailed research summary covering important aspects, recent developments, and insights related to the topic.\",\n",
        "        agent=researcher\n",
        "    )\n",
        "\n",
        "    writing_task = Task(\n",
        "        description=f\"Using the research, write a full-length article on the topic: {topic} in 1500 words give various sub section\",\n",
        "        expected_output=\"An engaging, detailed, informative, and coherent article suitable for online publication.\",\n",
        "        agent=writer\n",
        "    )\n",
        "\n",
        "    editing_task = Task(\n",
        "        description=f\"Review and edit the article on {topic} for clarity, grammar, flow, and engagement.\",\n",
        "        expected_output=\"A polished, clear, and professionally edited final version of the article.\",\n",
        "        agent=editor\n",
        "    )\n",
        "\n",
        "    # Setup Crew\n",
        "    crew = Crew(\n",
        "        agents=[researcher, writer, editor],\n",
        "        tasks=[research_task, writing_task, editing_task],\n",
        "        verbose=True  # Set to False if you want less console output\n",
        "    )\n",
        "\n",
        "    # Execute\n",
        "    result = crew.kickoff()\n",
        "    return result\n",
        "\n",
        "# Gradio Interface\n",
        "def generate_article(topic):\n",
        "    return run_crewai_article_writer(topic)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_article,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter a topic for the article...\"),\n",
        "    outputs=gr.Textbox(lines=20, label=\"Generated Article\"),\n",
        "    title=\"DDS AI Residency Free Masterclass\",\n",
        "    description=\"Enter a topic and let CrewAI agents research, write, and edit a complete article!\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}